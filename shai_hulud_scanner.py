#!/usr/bin/env python3
"""
Shai-Hulud 2.0 Scanner
"""

import json
import sys
import os
import re
import csv
import urllib.request
from typing import Dict, List, Set, Tuple, Optional
from pathlib import Path
from datetime import datetime

# URL —Å–ø–∏—Å–∫–∞ IOCs –æ—Ç Datadog
DATADOG_IOCS_URL = "https://raw.githubusercontent.com/DataDog/indicators-of-compromise/main/shai-hulud-2.0/consolidated_iocs.csv"
LOCAL_IOCS_FILE = Path(__file__).parent / "consolidated_iocs.csv"

# –ë–∞–∑–æ–≤—ã–π —Å–ø–∏—Å–æ–∫ (–µ—Å–ª–∏ –Ω–µ —É–¥–∞–µ—Ç—Å—è –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏–∑ GitHub)
FALLBACK_COMPROMISED_PACKAGES = {
    "zapier-platform-core": ["0.15.0", "0.15.1"],
    "zapier-platform-cli": ["18.0.0", "18.0.1"],
    "zapier-sdk": ["1.0.0"],
    "@asyncapi/specs": ["7.6.4"],
    "@asyncapi/parser": ["3.3.1"],
    "@asyncapi/modelina": ["4.3.0"],
    "posthog-node": ["4.2.1"],
    "posthog-js": ["1.165.0"],
    "@postman/postman-mcp-cli": ["0.1.0"],
    "@ensdomains/ensjs": ["4.1.0"],
    "@browserbasehq/sdk": ["1.5.0"],
}

# –ò–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã –∫–æ–º–ø—Ä–æ–º–µ—Ç–∞—Ü–∏–∏
MALICIOUS_INDICATORS = [
    "setup_bun.js",
    "bun_environment.js",
    "SHA1HULUD",
    "Sha1-Hulud",
    "Shai-Hulud",
]

# –ü–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω—ã–µ —Å–∫—Ä–∏–ø—Ç—ã
SUSPICIOUS_SCRIPT_PATTERNS = [
    r"curl.*https?://[^\s]+",
    r"wget.*https?://[^\s]+",
    r"bash.*<<.*EOF",
    r"node.*setup_bun",
    r"bun.*bun_environment",
    r"npm.*publish",
]

# –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è JS/TS —Ñ–∞–π–ª–æ–≤
JS_MALICIOUS_PATTERNS = {
    'credential_theft_git': r'(?:fs\.read(?:File)?Sync\([^)]*[\'"]\.git(?:config|credentials)|\.git(?:config|credentials)[\'"])',
    'credential_theft_npm': r'(?:fs\.read(?:File)?Sync\([^)]*[\'"]\.npmrc|\.npmrc[\'"])',
    'credential_theft_aws': r'(?:fs\.read(?:File)?Sync\([^)]*[\'"]\.aws[/\\]credentials|\.aws[/\\]credentials[\'"])',
    'credential_theft_gcp': r'(?:fs\.read(?:File)?Sync\([^)]*[\'"]\.config[/\\]gcloud|\.config[/\\]gcloud)',
    'credential_theft_azure': r'(?:fs\.read(?:File)?Sync\([^)]*[\'"]\.azure|\.azure[/\\])',
    'trufflehog_usage': r'(?:spawn|exec|execSync)\([\'"]trufflehog',
    'github_exfiltration': r'(?:fetch|axios\.(?:post|get))\([\'"]https://api\.github\.com',
    'metadata_service': r'(?:fetch|axios\.get)\([\'"]https?://(?:169\.254\.169\.254|metadata\.google\.internal)',
    'ioc_files': r'fs\.writeFileSync\([^)]*[\'"](?:cloud|contents|environment|truffleSecrets|actionsSecrets)\.json',
    'double_base64': r'Buffer\.from\(Buffer\.from\([^)]+,\s*[\'"]base64[\'"]\)\.toString\(\)',
    'env_scraping': r'JSON\.stringify\(process\.env\)',
    'ci_detection': r'process\.env\.(?:GITHUB_ACTIONS|CI|BUILDKITE|CODEBUILD_BUILD_NUMBER|CIRCLE_SHA1|PROJECT_ID)',
    'home_destruction': r'fs\.(?:rm|rmdir)Sync\([^)]*(?:HOME|home|~)',
    'bun_install': r'(?:exec|execSync)\([\'"]curl\s+https://bun\.sh/install',
    'runner_registration': r'(?:fetch|axios\.post)\([^\)]*actions/runners/registration-token',
    'datadog_credentials': r'process\.env\.(?:DD_API_KEY|DATADOG_API_KEY|DD_APP_KEY)',
}

# –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è GitHub Actions workflows
WORKFLOW_MALICIOUS_PATTERNS = {
    'discussion_injection': r'on:\s*discussion:.*\$\{\{\s*github\.event\.discussion\.body\s*\}\}',
    'self_hosted_runner': r'runs-on:\s*self-hosted',
    'formatter_workflow': r'formatter_\d+\.yml',
    'secrets_artifact': r'(?:secrets|credentials|cloud|environment|truffle).*\.(?:json|txt)',
}


def load_compromised_packages(update: bool = False) -> Dict[str, List[str]]:
    """–ó–∞–≥—Ä—É–∑–∫–∞ —Å–ø–∏—Å–∫–∞ —Å–∫–æ–º–ø—Ä–æ–º–µ—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø–∞–∫–µ—Ç–æ–≤"""

    # –ü–æ–ø—ã—Ç–∫–∞ –æ–±–Ω–æ–≤–∏—Ç—å –∏–∑ GitHub
    if update and not LOCAL_IOCS_FILE.exists():
        print("üì• –ó–∞–≥—Ä—É–∑–∫–∞ –∞–∫—Ç—É–∞–ª—å–Ω–æ–≥–æ —Å–ø–∏—Å–∫–∞ IOCs –∏–∑ GitHub...")
        try:
            urllib.request.urlretrieve(DATADOG_IOCS_URL, LOCAL_IOCS_FILE)
            print(f"‚úÖ –°–ø–∏—Å–æ–∫ –æ–±–Ω–æ–≤–ª–µ–Ω: {LOCAL_IOCS_FILE}")
        except Exception as e:
            print(f"‚ö†Ô∏è  –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Å–ø–∏—Å–æ–∫: {e}")
            print("   –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è fallback —Å–ø–∏—Å–æ–∫")

    # –ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑ –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ CSV
    if LOCAL_IOCS_FILE.exists():
        try:
            compromised = {}
            with open(LOCAL_IOCS_FILE, 'r', encoding='utf-8') as f:
                reader = csv.DictReader(f)
                for row in reader:
                    package_name = row['package_name']
                    versions = row['package_versions'].split(',')
                    # –û—á–∏—Å—Ç–∫–∞ –≤–µ—Ä—Å–∏–π
                    versions = [v.strip() for v in versions]
                    compromised[package_name] = versions

            print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(compromised)} —Å–∫–æ–º–ø—Ä–æ–º–µ—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø–∞–∫–µ—Ç–æ–≤ –∏–∑ IOCs")
            return compromised
        except Exception as e:
            print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è IOCs: {e}")

    print(f"‚ö†Ô∏è  –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è fallback —Å–ø–∏—Å–æ–∫ ({len(FALLBACK_COMPROMISED_PACKAGES)} –ø–∞–∫–µ—Ç–æ–≤)")
    return FALLBACK_COMPROMISED_PACKAGES


class LockFileParser:
    """–ü–∞—Ä—Å–µ—Ä –¥–ª—è —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ç–∏–ø–æ–≤ lock —Ñ–∞–π–ª–æ–≤"""

    @staticmethod
    def parse_package_lock(lock_path: Path) -> Dict[str, str]:
        """–ü–∞—Ä—Å–∏–Ω–≥ package-lock.json (npm)"""
        try:
            with open(lock_path, 'r', encoding='utf-8') as f:
                data = json.load(f)

            packages = {}

            # npm v1/v2 format
            if 'dependencies' in data:
                LockFileParser._extract_npm_v1_deps(data['dependencies'], packages)

            # npm v3 (lockfileVersion 3) format
            if 'packages' in data:
                for pkg_path, pkg_data in data['packages'].items():
                    if pkg_path and pkg_path != '':
                        pkg_name = pkg_path.replace('node_modules/', '')
                        if 'version' in pkg_data:
                            packages[pkg_name] = pkg_data['version']

            return packages
        except Exception as e:
            print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ package-lock.json: {e}")
            return {}

    @staticmethod
    def _extract_npm_v1_deps(deps: Dict, packages: Dict[str, str]):
        """–†–µ–∫—É—Ä—Å–∏–≤–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π –∏–∑ npm v1/v2 —Ñ–æ—Ä–º–∞—Ç–∞"""
        for name, data in deps.items():
            if isinstance(data, dict) and 'version' in data:
                packages[name] = data['version']
                if 'dependencies' in data:
                    LockFileParser._extract_npm_v1_deps(data['dependencies'], packages)

    @staticmethod
    def parse_yarn_lock(lock_path: Path) -> Dict[str, str]:
        """–ü–∞—Ä—Å–∏–Ω–≥ yarn.lock"""
        try:
            with open(lock_path, 'r', encoding='utf-8') as f:
                content = f.read()

            packages = {}
            pattern = r'"?([^"@\s]+)@[^"]*"?:\s*\n\s*version\s+"([^"]+)"'
            matches = re.findall(pattern, content)

            for pkg_name, version in matches:
                packages[pkg_name] = version

            return packages
        except Exception as e:
            print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ yarn.lock: {e}")
            return {}

    @staticmethod
    def parse_pnpm_lock(lock_path: Path) -> Dict[str, str]:
        """–ü–∞—Ä—Å–∏–Ω–≥ pnpm-lock.yaml (–ø—Ä–æ—Å—Ç–æ–π –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π –ø–∞—Ä—Å–µ—Ä –±–µ–∑ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π)"""
        try:
            with open(lock_path, 'r', encoding='utf-8') as f:
                content = f.read()

            packages = {}

            # –ü—Ä–æ—Å—Ç–æ–π –ø–∞—Ä—Å–∏–Ω–≥ –¥–ª—è pnpm v6+ (—Å–µ–∫—Ü–∏—è packages:)
            # –§–æ—Ä–º–∞—Ç: /package/version –∏–ª–∏ /package@version
            in_packages_section = False
            for line in content.split('\n'):
                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å–µ–∫—Ü–∏—é packages
                if line.strip() == 'packages:':
                    in_packages_section = True
                    continue
                
                # –í—ã—Ö–æ–¥ –∏–∑ —Å–µ–∫—Ü–∏–∏ –ø—Ä–∏ –Ω–æ–≤–æ–π top-level —Å–µ–∫—Ü–∏–∏
                if in_packages_section and line and not line.startswith(' ') and not line.startswith('\t'):
                    in_packages_section = False
                
                if in_packages_section and line.strip():
                    # –ò—â–µ–º —Å—Ç—Ä–æ–∫–∏ –≤–∏–¥–∞: '/package/version:' –∏–ª–∏ '/package@version:'
                    match = re.match(r'\s+[\'"]?/(.+?)[@/](\d+\.\d+\.\d+[^\s:\'"]*)[\'":]', line)
                    if match:
                        pkg_name = match.group(1)
                        version = match.group(2)
                        packages[pkg_name] = version

            return packages
        except Exception as e:
            print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ pnpm-lock.yaml: {e}")
            return {}


class ShaiHuludDetectorFinal:
    def __init__(self, project_path: str, update_iocs: bool = False, deep_scan: bool = True):
        self.project_path = Path(project_path)
        self.findings: List[Dict] = []
        self.all_packages: Dict[str, str] = {}
        self.compromised_packages = load_compromised_packages(update=update_iocs)
        self.deep_scan = deep_scan
        self.scanned_files = 0
        self.start_time = datetime.now()

    def scan(self) -> bool:
        """–í—ã–ø–æ–ª–Ω–∏—Ç—å –ø–æ–ª–Ω–æ–µ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞"""
        print(f"\nüîç –°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞: {self.project_path}")
        print("=" * 70)

        if self.project_path.is_file():
            project_dir = self.project_path.parent
        else:
            project_dir = self.project_path

        # –°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
        self._scan_dependencies(project_dir)
        
        # –ì–ª—É–±–æ–∫–æ–µ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–æ–≤ (–µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–æ)
        if self.deep_scan:
            print(f"\nÔøΩ –ì–ª—É–±–æ–∫–æ–µ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ –∫–æ–¥–∞...")
            self._scan_js_files(project_dir)
            self._scan_workflows(project_dir)
            self._scan_malicious_files(project_dir)

        return self._print_results()

    def _scan_dependencies(self, project_dir: Path):
        """–°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–æ–≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π"""
        print(f"\nÔøΩüì¶ –ü–æ–∏—Å–∫ —Ñ–∞–π–ª–æ–≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π...")

        # –°–∫–∞–Ω–∏—Ä—É–µ–º package.json
        package_json_path = project_dir / 'package.json'
        if package_json_path.exists():
            print(f"  ‚úì package.json")
            self._scan_package_json(package_json_path)
            self.scanned_files += 1

        # –°–∫–∞–Ω–∏—Ä—É–µ–º lock —Ñ–∞–π–ª—ã
        lock_files_found = []

        package_lock_path = project_dir / 'package-lock.json'
        if package_lock_path.exists():
            print(f"  ‚úì package-lock.json")
            lock_files_found.append('npm')
            packages = LockFileParser.parse_package_lock(package_lock_path)
            self._check_lock_packages(packages, 'package-lock.json')
            self.scanned_files += 1

        yarn_lock_path = project_dir / 'yarn.lock'
        if yarn_lock_path.exists():
            print(f"  ‚úì yarn.lock")
            lock_files_found.append('yarn')
            packages = LockFileParser.parse_yarn_lock(yarn_lock_path)
            self._check_lock_packages(packages, 'yarn.lock')
            self.scanned_files += 1

        pnpm_lock_path = project_dir / 'pnpm-lock.yaml'
        if pnpm_lock_path.exists():
            print(f"  ‚úì pnpm-lock.yaml")
            lock_files_found.append('pnpm')
            packages = LockFileParser.parse_pnpm_lock(pnpm_lock_path)
            self._check_lock_packages(packages, 'pnpm-lock.yaml')
            self.scanned_files += 1

        bun_lock_path = project_dir / 'bun.lockb'
        if bun_lock_path.exists():
            print(f"  ‚ö†Ô∏è  bun.lockb (–±–∏–Ω–∞—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç - –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è)")

        if not lock_files_found and not package_json_path.exists():
            print(f"\n‚ö†Ô∏è  –ù–µ –Ω–∞–π–¥–µ–Ω–æ —Ñ–∞–π–ª–æ–≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π –≤ {project_dir}")

        if self.all_packages:
            print(f"\nüìä –ü—Ä–æ–≤–µ—Ä–µ–Ω–æ –ø–∞–∫–µ—Ç–æ–≤: {len(self.all_packages)}")
        print(f"üìä –ë–∞–∑–∞ IOCs: {len(self.compromised_packages)} —Å–∫–æ–º–ø—Ä–æ–º–µ—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø–∞–∫–µ—Ç–æ–≤")

    def _scan_js_files(self, project_dir: Path):
        """–°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ JS/TS —Ñ–∞–π–ª–æ–≤ –Ω–∞ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –∞—Ç–∞–∫–∏"""
        # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –ø–æ–∏—Å–∫–∞ JS/TS —Ñ–∞–π–ª–æ–≤
        patterns = ['**/*.js', '**/*.ts', '**/*.jsx', '**/*.tsx']
        
        js_files = []
        for pattern in patterns:
            for file_path in project_dir.glob(pattern):
                # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º node_modules –∏ —Å–∫—Ä—ã—Ç—ã–µ –ø–∞–ø–∫–∏
                if 'node_modules' in file_path.parts or any(p.startswith('.') for p in file_path.parts[:-1]):
                    continue
                js_files.append(file_path)
        
        if not js_files:
            return
        
        print(f"  üìÑ –ù–∞–π–¥–µ–Ω–æ {len(js_files)} JS/TS —Ñ–∞–π–ª–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞...")
        
        for file_path in js_files:
            self._scan_js_file(file_path)
            self.scanned_files += 1

    def _scan_js_file(self, file_path: Path):
        """–°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –æ–¥–Ω–æ–≥–æ JS/TS —Ñ–∞–π–ª–∞"""
        try:
            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                content = f.read()
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã –≤ —Å–æ–¥–µ—Ä–∂–∏–º–æ–º
            for indicator in MALICIOUS_INDICATORS:
                if indicator in content:
                    self.findings.append({
                        'severity': 'CRITICAL',
                        'type': 'malicious_indicator_in_file',
                        'file': str(file_path.relative_to(self.project_path)),
                        'indicator': indicator,
                        'message': f'–ò–Ω–¥–∏–∫–∞—Ç–æ—Ä Shai-Hulud –≤ —Ñ–∞–π–ª–µ: {indicator}'
                    })
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –≤—Ä–µ–¥–æ–Ω–æ—Å–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã
            for pattern_name, pattern_regex in JS_MALICIOUS_PATTERNS.items():
                matches = re.finditer(pattern_regex, content, re.MULTILINE | re.DOTALL)
                for match in matches:
                    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º severity –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –ø–∞—Ç—Ç–µ—Ä–Ω–∞
                    severity = 'CRITICAL' if pattern_name in [
                        'credential_theft_git', 'credential_theft_npm', 'credential_theft_aws',
                        'trufflehog_usage', 'ioc_files', 'home_destruction', 'runner_registration'
                    ] else 'HIGH' if pattern_name in [
                        'github_exfiltration', 'metadata_service', 'bun_install'
                    ] else 'WARNING'
                    
                    # –ü–æ–ª—É—á–∞–µ–º –Ω–æ–º–µ—Ä —Å—Ç—Ä–æ–∫–∏
                    line_num = content[:match.start()].count('\n') + 1
                    
                    self.findings.append({
                        'severity': severity,
                        'type': f'js_pattern_{pattern_name}',
                        'file': str(file_path.relative_to(self.project_path)),
                        'line': line_num,
                        'pattern': pattern_name,
                        'message': f'–û–±–Ω–∞—Ä—É–∂–µ–Ω –ø–∞—Ç—Ç–µ—Ä–Ω {pattern_name} (—Å—Ç—Ä–æ–∫–∞ {line_num})'
                    })
        
        except Exception as e:
            # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º –æ—à–∏–±–∫–∏ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–æ–≤
            pass

    def _scan_workflows(self, project_dir: Path):
        """–°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ GitHub Actions workflows"""
        workflows_dir = project_dir / '.github' / 'workflows'
        
        if not workflows_dir.exists():
            return
        
        workflow_files = list(workflows_dir.glob('*.yml')) + list(workflows_dir.glob('*.yaml'))
        
        if not workflow_files:
            return
        
        print(f"  üîß –ù–∞–π–¥–µ–Ω–æ {len(workflow_files)} workflow —Ñ–∞–π–ª–æ–≤...")
        
        for workflow_file in workflow_files:
            self._scan_workflow_file(workflow_file)
            self.scanned_files += 1

    def _scan_workflow_file(self, file_path: Path):
        """–°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ workflow —Ñ–∞–π–ª–∞"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞
            if file_path.name == 'discussion.yaml' or file_path.name == 'discussion.yml':
                self.findings.append({
                    'severity': 'CRITICAL',
                    'type': 'malicious_workflow_file',
                    'file': str(file_path.relative_to(self.project_path)),
                    'message': '–û–±–Ω–∞—Ä—É–∂–µ–Ω –ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω—ã–π workflow: discussion.yaml'
                })
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ formatter workflow
            if re.match(r'formatter_\d+\.ya?ml', file_path.name):
                self.findings.append({
                    'severity': 'CRITICAL',
                    'type': 'malicious_workflow_file',
                    'file': str(file_path.relative_to(self.project_path)),
                    'message': f'–û–±–Ω–∞—Ä—É–∂–µ–Ω –ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω—ã–π workflow: {file_path.name}'
                })
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤
            for indicator in MALICIOUS_INDICATORS:
                if indicator in content:
                    self.findings.append({
                        'severity': 'CRITICAL',
                        'type': 'malicious_indicator_in_workflow',
                        'file': str(file_path.relative_to(self.project_path)),
                        'indicator': indicator,
                        'message': f'–ò–Ω–¥–∏–∫–∞—Ç–æ—Ä Shai-Hulud –≤ workflow: {indicator}'
                    })
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –≤—Ä–µ–¥–æ–Ω–æ—Å–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã
            for pattern_name, pattern_regex in WORKFLOW_MALICIOUS_PATTERNS.items():
                if re.search(pattern_regex, content, re.MULTILINE | re.DOTALL):
                    self.findings.append({
                        'severity': 'CRITICAL',
                        'type': f'workflow_pattern_{pattern_name}',
                        'file': str(file_path.relative_to(self.project_path)),
                        'pattern': pattern_name,
                        'message': f'–û–±–Ω–∞—Ä—É–∂–µ–Ω –ø–∞—Ç—Ç–µ—Ä–Ω {pattern_name} –≤ workflow'
                    })
        
        except Exception as e:
            pass

    def _scan_malicious_files(self, project_dir: Path):
        """–ü–æ–∏—Å–∫ –∏–∑–≤–µ—Å—Ç–Ω—ã—Ö –≤—Ä–µ–¥–æ–Ω–æ—Å–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤"""
        malicious_files = ['setup_bun.js', 'bun_environment.js']
        
        for mal_file in malicious_files:
            # –ü–æ–∏—Å–∫ —Ñ–∞–π–ª–æ–≤ —Ä–µ–∫—É—Ä—Å–∏–≤–Ω–æ
            for found_file in project_dir.rglob(mal_file):
                # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º node_modules
                if 'node_modules' not in found_file.parts:
                    self.findings.append({
                        'severity': 'CRITICAL',
                        'type': 'known_malicious_file',
                        'file': str(found_file.relative_to(self.project_path)),
                        'message': f'–û–±–Ω–∞—Ä—É–∂–µ–Ω –∏–∑–≤–µ—Å—Ç–Ω—ã–π –≤—Ä–µ–¥–æ–Ω–æ—Å–Ω—ã–π —Ñ–∞–π–ª: {mal_file}'
                    })
                    self.scanned_files += 1

    def _scan_package_json(self, package_json_path: Path):
        """–°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ package.json"""
        try:
            with open(package_json_path, 'r', encoding='utf-8') as f:
                data = json.load(f)

            self._check_compromised_packages(data, 'package.json')
            self._check_malicious_scripts(data)
            self._check_file_references(data)
            self._check_repository_info(data)
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è package.json: {e}")

    def _check_lock_packages(self, packages: Dict[str, str], source: str):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–∞–∫–µ—Ç–æ–≤ –∏–∑ lock —Ñ–∞–π–ª–∞"""
        for pkg_name, version in packages.items():
            self.all_packages[pkg_name] = version

            if pkg_name in self.compromised_packages:
                clean_version = re.sub(r'^[^0-9]*', '', version)

                if clean_version in self.compromised_packages[pkg_name]:
                    self.findings.append({
                        'severity': 'CRITICAL',
                        'type': 'compromised_package_lock',
                        'source': source,
                        'package': pkg_name,
                        'version': version,
                        'message': f'[{source}] –°–∫–æ–º–ø—Ä–æ–º–µ—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π: {pkg_name}@{version}'
                    })

    def _check_compromised_packages(self, package_json: Dict, source: str):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π –∏–∑ package.json"""
        sections = ['dependencies', 'devDependencies', 'optionalDependencies']

        for section in sections:
            if section not in package_json:
                continue

            for package, version in package_json[section].items():
                if package in self.compromised_packages:
                    clean_version = re.sub(r'^[^0-9]*', '', version)

                    if clean_version in self.compromised_packages[package]:
                        self.findings.append({
                            'severity': 'CRITICAL',
                            'type': 'compromised_package',
                            'section': section,
                            'package': package,
                            'version': version,
                            'message': f'[package.json] –°–∫–æ–º–ø—Ä–æ–º–µ—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π: {package}@{version}'
                        })

    def _check_malicious_scripts(self, package_json: Dict):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ scripts —Å–µ–∫—Ü–∏–∏"""
        if 'scripts' not in package_json:
            return

        scripts = package_json['scripts']

        for script_name, script_content in scripts.items():
            for indicator in MALICIOUS_INDICATORS:
                if indicator in script_content:
                    self.findings.append({
                        'severity': 'CRITICAL',
                        'type': 'malicious_indicator',
                        'script': script_name,
                        'indicator': indicator,
                        'message': f'–ò–Ω–¥–∏–∫–∞—Ç–æ—Ä Shai-Hulud: {indicator}'
                    })

            for pattern in SUSPICIOUS_SCRIPT_PATTERNS:
                if re.search(pattern, script_content):
                    self.findings.append({
                        'severity': 'WARNING',
                        'type': 'suspicious_script',
                        'script': script_name,
                        'message': f'–ü–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω—ã–π —Å–∫—Ä–∏–ø—Ç: {script_name}'
                    })

            if script_name in ['preinstall', 'postinstall', 'install']:
                if any(word in script_content.lower() for word in ['curl', 'wget', 'bun', 'github']):
                    self.findings.append({
                        'severity': 'HIGH',
                        'type': 'suspicious_lifecycle_script',
                        'script': script_name,
                        'message': f'–ü–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω—ã–π {script_name}'
                    })

    def _check_file_references(self, package_json: Dict):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Ñ–∞–π–ª–æ–≤—ã—Ö —Å—Å—ã–ª–æ–∫"""
        for field in ['main', 'bin', 'browser']:
            if field in package_json:
                value = package_json[field]
                if isinstance(value, str):
                    for indicator in MALICIOUS_INDICATORS:
                        if indicator in value:
                            self.findings.append({
                                'severity': 'CRITICAL',
                                'type': 'malicious_file_reference',
                                'field': field,
                                'message': f'–ü–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω—ã–π —Ñ–∞–π–ª –≤ "{field}": {value}'
                            })

    def _check_repository_info(self, package_json: Dict):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è"""
        if 'repository' in package_json:
            repo = package_json['repository']
            repo_url = repo if isinstance(repo, str) else repo.get('url', '')

            if any(indicator in repo_url for indicator in ['Sha1-Hulud', 'SHA1HULUD']):
                self.findings.append({
                    'severity': 'CRITICAL',
                    'type': 'malicious_repository',
                    'message': '–†–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π Shai-Hulud!'
                })

    def _print_results(self) -> bool:
        """–í—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"""
        elapsed_time = (datetime.now() - self.start_time).total_seconds()
        
        print(f"\n{'=' * 70}")
        print(f"üìä –°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ")
        print(f"{'=' * 70}")
        print(f"‚è±Ô∏è  –í—Ä–µ–º—è: {elapsed_time:.2f}s")
        print(f"üìÑ –ü—Ä–æ–≤–µ—Ä–µ–Ω–æ —Ñ–∞–π–ª–æ–≤: {self.scanned_files}")
        print(f"üì¶ –ü—Ä–æ–≤–µ—Ä–µ–Ω–æ –ø–∞–∫–µ—Ç–æ–≤: {len(self.all_packages)}")
        
        if not self.findings:
            print("\n‚úÖ –ò–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤ Shai-Hulud 2.0 –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ")
            print("‚úÖ –ü—Ä–æ–µ–∫—Ç –±–µ–∑–æ–ø–∞—Å–µ–Ω")
            return True

        critical = [f for f in self.findings if f['severity'] == 'CRITICAL']
        high = [f for f in self.findings if f['severity'] == 'HIGH']
        warnings = [f for f in self.findings if f['severity'] == 'WARNING']

        print(f"\nüö® –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ {len(self.findings)} –ø—Ä–æ–±–ª–µ–º:")
        print(f"   ‚îú‚îÄ üî¥ CRITICAL: {len(critical)}")
        print(f"   ‚îú‚îÄ üü† HIGH: {len(high)}")
        print(f"   ‚îî‚îÄ üü° WARNING: {len(warnings)}\n")

        # –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –ø–æ —Ç–∏–ø–∞–º
        findings_by_type = {}
        for finding in self.findings:
            ftype = finding['type']
            if ftype not in findings_by_type:
                findings_by_type[ftype] = []
            findings_by_type[ftype].append(finding)

        # –î–µ—Ç–∞–ª—å–Ω—ã–π –≤—ã–≤–æ–¥
        print(f"{'=' * 70}")
        print("üîç –î–µ—Ç–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã:")
        print(f"{'=' * 70}\n")
        
        for finding in critical + high + warnings:
            emoji = "üî¥" if finding['severity'] == 'CRITICAL' else "üü†" if finding['severity'] == 'HIGH' else "üü°"
            print(f"{emoji} [{finding['severity']}] {finding['type']}")
            print(f"   {finding['message']}")

            for key, value in finding.items():
                if key not in ['severity', 'type', 'message']:
                    print(f"   ‚Ä¢ {key}: {value}")
            print()

        if len(critical) > 0:
            print(f"{'=' * 70}")
            print("‚ö†Ô∏è  –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –£–ì–†–û–ó–ê –û–ë–ù–ê–†–£–ñ–ï–ù–ê!")
            print(f"{'=' * 70}\n")
            print("üõ°Ô∏è  –ù–µ–º–µ–¥–ª–µ–Ω–Ω—ã–µ –¥–µ–π—Å—Ç–≤–∏—è:")
            print("1. üîí –ò–∑–æ–ª–∏—Ä—É–π—Ç–µ —Å–∏—Å—Ç–µ–º—É –æ—Ç —Å–µ—Ç–∏")
            print("2. üîë –†–æ—Ç–∏—Ä—É–π—Ç–µ –≤—Å–µ credentials:")
            print("   ‚Ä¢ GitHub tokens (Settings ‚Üí Developer settings ‚Üí Revoke all)")
            print("   ‚Ä¢ NPM tokens (npm token revoke --all)")
            print("   ‚Ä¢ AWS credentials (aws iam delete-access-key)")
            print("   ‚Ä¢ GCP credentials (gcloud auth revoke --all)")
            print("   ‚Ä¢ Azure credentials")
            print("3. üîç –ü—Ä–æ–≤–µ—Ä—å—Ç–µ GitHub –Ω–∞ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏ 'Sha1-Hulud: The Second Coming'")
            print("4. ü§ñ –ü—Ä–æ–≤–µ—Ä—å—Ç–µ self-hosted runners —Å –∏–º–µ–Ω–µ–º 'SHA1HULUD'")
            print("5. üóëÔ∏è  –£–¥–∞–ª–∏—Ç–µ node_modules –∏ –ø–µ—Ä–µ—É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ —á–∏—Å—Ç—ã–µ –≤–µ—Ä—Å–∏–∏:")
            print("   rm -rf node_modules package-lock.json")
            print("   npm install --ignore-scripts")
            print("6. üìã –ü—Ä–æ–≤–µ—Ä—å—Ç–µ .github/workflows/discussion.yaml")
            print("7. üìä –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ª–æ–≥–∏ –Ω–∞ –Ω–µ—Å–∞–Ω–∫—Ü–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–µ–π—Å—Ç–≤–∏—è")
            print("\nüìñ –ü–æ–¥—Ä–æ–±–Ω–µ–µ: https://securitylabs.datadoghq.com/articles/shai-hulud-2.0-npm-worm/")

        return len(critical) == 0

    def generate_json_report(self, output_file: str = "shai-hulud-scan-report.json") -> None:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è JSON –æ—Ç—á—ë—Ç–∞"""
        report = {
            'scan_info': {
                'target': str(self.project_path),
                'timestamp': datetime.now().isoformat(),
                'elapsed_seconds': (datetime.now() - self.start_time).total_seconds(),
                'scanned_files': self.scanned_files,
                'scanned_packages': len(self.all_packages),
                'iocs_database_size': len(self.compromised_packages),
            },
            'summary': {
                'total_findings': len(self.findings),
                'critical': len([f for f in self.findings if f['severity'] == 'CRITICAL']),
                'high': len([f for f in self.findings if f['severity'] == 'HIGH']),
                'warning': len([f for f in self.findings if f['severity'] == 'WARNING']),
            },
            'findings': self.findings,
            'packages_checked': self.all_packages,
        }
        
        output_path = Path(output_file)
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        print(f"\nüìÑ JSON –æ—Ç—á—ë—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {output_path.absolute()}")


def scan_directory(directory: str, update_iocs: bool = False, deep_scan: bool = True) -> bool:
    """–†–µ–∫—É—Ä—Å–∏–≤–Ω–æ–µ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏"""
    directory_path = Path(directory)

    if not directory_path.exists():
        print(f"‚ùå –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç: {directory}")
        sys.exit(1)

    # –ü–æ–∏—Å–∫ –ø—Ä–æ–µ–∫—Ç–æ–≤ —Å package.json
    projects = set()
    for package_json in directory_path.rglob('package.json'):
        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º node_modules
        if 'node_modules' not in package_json.parts:
            projects.add(package_json.parent)

    if not projects:
        print(f"‚ö†Ô∏è  –ü—Ä–æ–µ–∫—Ç—ã —Å package.json –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ {directory}")
        return True

    print(f"\nüì¶ –ù–∞–π–¥–µ–Ω–æ {len(projects)} –ø—Ä–æ–µ–∫—Ç–æ–≤ –¥–ª—è —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è")
    print(f"üî¨ –†–µ–∂–∏–º: {'–ì–ª—É–±–æ–∫–æ–µ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ' if deep_scan else '–¢–æ–ª—å–∫–æ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏'}\n")

    all_clean = True
    total_findings = 0
    
    for i, project_dir in enumerate(sorted(projects), 1):
        print(f"\n{'=' * 70}")
        print(f"–ü—Ä–æ–µ–∫—Ç {i}/{len(projects)}: {project_dir.name}")
        print(f"{'=' * 70}")
        
        detector = ShaiHuludDetectorFinal(str(project_dir), update_iocs=update_iocs, deep_scan=deep_scan)
        is_clean = detector.scan()

        if not is_clean:
            all_clean = False
            total_findings += len(detector.findings)

    print(f"\n{'=' * 70}")
    print(f"üìä –ò—Ç–æ–≥–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞")
    print(f"{'=' * 70}")
    print(f"–í—Å–µ–≥–æ –ø—Ä–æ–µ–∫—Ç–æ–≤: {len(projects)}")
    print(f"–ß–∏—Å—Ç—ã—Ö –ø—Ä–æ–µ–∫—Ç–æ–≤: {sum(1 for _ in projects) - (0 if all_clean else 1)}")
    print(f"–ü—Ä–æ–±–ª–µ–º–Ω—ã—Ö –ø—Ä–æ–µ–∫—Ç–æ–≤: {0 if all_clean else 1}")
    print(f"–í—Å–µ–≥–æ –Ω–∞—Ö–æ–¥–æ–∫: {total_findings}")
    
    if all_clean:
        print("\n‚úÖ –í—Å–µ –ø—Ä–æ–µ–∫—Ç—ã –±–µ–∑–æ–ø–∞—Å–Ω—ã!")
        return True
    else:
        print("\nüö® –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–µ —É–≥—Ä–æ–∑—ã!")
        return False


def main():
    import argparse

    parser = argparse.ArgumentParser(
        description='Shai-Hulud 2.0 Scanner - –∫–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –¥–µ—Ç–µ–∫—Ç–æ—Ä –∞—Ç–∞–∫–∏ Shai-Hulud 2.0',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
–ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è:
  %(prog)s ./my-project                    # –°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –æ–¥–Ω–æ–≥–æ –ø—Ä–æ–µ–∫—Ç–∞
  %(prog)s ./package.json                  # –°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
  %(prog)s ~/projects --recursive          # –†–µ–∫—É—Ä—Å–∏–≤–Ω–æ–µ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ
  %(prog)s . --update-iocs                 # –û–±–Ω–æ–≤–∏—Ç—å –±–∞–∑—É IOCs
  %(prog)s . --quick                       # –ë—ã—Å—Ç—Ä–æ–µ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ (—Ç–æ–ª—å–∫–æ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏)
  %(prog)s . --json-report report.json     # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å JSON –æ—Ç—á—ë—Ç

–£—Ä–æ–≤–Ω–∏ severity:
  üî¥ CRITICAL - –ü—Ä—è–º—ã–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã –∞—Ç–∞–∫–∏, —Ç—Ä–µ–±—É–µ—Ç –Ω–µ–º–µ–¥–ª–µ–Ω–Ω—ã—Ö –¥–µ–π—Å—Ç–≤–∏–π
  üü† HIGH     - –ü–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω–æ–µ –ø–æ–≤–µ–¥–µ–Ω–∏–µ, —Ç—Ä–µ–±—É–µ—Ç –ø—Ä–æ–≤–µ—Ä–∫–∏
  üü° WARNING  - –ü–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω–æ –æ–ø–∞—Å–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã

–ü–æ–¥—Ä–æ–±–Ω–µ–µ: https://github.com/DataDog/indicators-of-compromise/tree/main/shai-hulud-2.0
        """
    )
    
    parser.add_argument('path', help='–ü—É—Ç—å –∫ –ø—Ä–æ–µ–∫—Ç—É, package.json –∏–ª–∏ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏')
    parser.add_argument('--update-iocs', action='store_true',
                       help='–û–±–Ω–æ–≤–∏—Ç—å —Å–ø–∏—Å–æ–∫ IOCs –∏–∑ GitHub (Datadog)')
    parser.add_argument('--quick', action='store_true',
                       help='–ë—ã—Å—Ç—Ä–æ–µ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ (—Ç–æ–ª—å–∫–æ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏, –±–µ–∑ –≥–ª—É–±–æ–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –∫–æ–¥–∞)')
    parser.add_argument('--recursive', '-r', action='store_true',
                       help='–†–µ–∫—É—Ä—Å–∏–≤–Ω–æ–µ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –≤—Å–µ—Ö –ø—Ä–æ–µ–∫—Ç–æ–≤ –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏')
    parser.add_argument('--json-report', metavar='FILE',
                       help='–°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ JSON —Ñ–∞–π–ª')
    parser.add_argument('--version', action='version', version='%(prog)s 1.0.0 (Final)')
    
    args = parser.parse_args()

    target_path = Path(args.path)
    deep_scan = not args.quick

    if not target_path.exists():
        print(f"‚ùå –ù–µ–≤–∞–ª–∏–¥–Ω—ã–π –ø—É—Ç—å: {args.path}")
        sys.exit(1)

    # –†–µ–∫—É—Ä—Å–∏–≤–Ω–æ–µ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
    if args.recursive and target_path.is_dir():
        is_clean = scan_directory(args.path, update_iocs=args.update_iocs, deep_scan=deep_scan)
        sys.exit(0 if is_clean else 1)
    
    # –°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –æ–¥–Ω–æ–≥–æ –ø—Ä–æ–µ–∫—Ç–∞
    if target_path.is_file() or target_path.is_dir():
        detector = ShaiHuludDetectorFinal(args.path, update_iocs=args.update_iocs, deep_scan=deep_scan)
        is_clean = detector.scan()
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ JSON –æ—Ç—á—ë—Ç–∞
        if args.json_report:
            detector.generate_json_report(args.json_report)
        
        sys.exit(0 if is_clean else 1)


if __name__ == "__main__":
    main()
